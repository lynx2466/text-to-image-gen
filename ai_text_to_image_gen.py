# -*- coding: utf-8 -*-
"""ai_text_to_image_gen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TIxvnAnxPzrbexsvtQnkN_itUewnp5Hg

#  Basic Text-to-Image Generator using Stable Diffusion

This project demonstrates a beginner-friendly implementation of a **text-to-image generator** using **Stable Diffusion**. Users can input any prompt, and the model will generate a unique image based on that text.

Built using the `diffusers` library from Hugging Face, it leverages a pre-trained image generation pipeline and can be easily extended for creative or research purposes.

##  Key Features

-  Uses a powerful **pre-trained Stable Diffusion model**.
-  Accepts **natural language prompts** for image generation.
-  Simple and minimal â€” runs with just a few lines of code.
-  Uses `diffusers`, `transformers`, and `torch` for efficient performance.
-  Integrated with **Hugging Face login** to access gated models.

##  How It Works

##  1. Installing the Tools We Need

Before we do anything fun, we need to set up our environment.  
We install three main libraries:

- **`diffusers`**: lets us easily use AI image generation models.
- **`transformers`**: supports the AI model under the hood.
- **`accelerate`**: makes sure the model runs efficiently on GPU or CPU.

These are like the tools and engines that power everything.
"""

!pip install diffusers transformers accelerate gradio --upgrade

import torch
from diffusers import StableDiffusionPipeline
from huggingface_hub import notebook_login
import gradio as gr

"""##  2. Logging into Hugging Face

The model we want to use (Stable Diffusion) is hosted on a platform called **Hugging Face**.  
Think of it like a library full of AI models. To borrow some advanced models, we need to **log in using our Hugging Face token**.

Once weâ€™re logged in, we can load powerful models that are otherwise restricted.
"""

notebook_login("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")

"""##  3. Loading the Stable Diffusion Model

Hereâ€™s where the magic begins! We load a **pre-trained Stable Diffusion model** using Hugging Faceâ€™s pipeline.  
This model has already been trained on millions of images, so it understands how to generate new ones from text descriptions.

We also send it to the **GPU (if available)** using `.to("cuda")`, which makes it work much faster than on a regular CPU.
"""

pipe = StableDiffusionPipeline.from_pretrained(
    "CompVis/stable-diffusion-v1-4",
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")  # Uses GPU

"""##  4. Asking the User for a Prompt

Next, we ask the user to type a sentence â€” called a **prompt** â€” describing the image they want to generate.  
For example:  
> _"A futuristic city floating in the clouds during sunset"_

The model reads this and begins to "imagine" how it could look visually.
"""

def generate_image(prompt):
    image = pipe(prompt).images[0]
    return image

"""##  5. Generating and Displaying the Image

Once the prompt is given, the model gets to work. It uses complex deep learning techniques (called **diffusion**) to build the image pixel by pixel.

Finally, we show the result using `.show()`.  
The AI just created an original image based on your idea â€” no internet, no copy-paste, just raw generative power. ðŸ¤¯

"""

gr.Interface(
    fn=generate_image,
    inputs=gr.Textbox(lines=2, placeholder="Describe the image you want..."),
    outputs="image",
    title=" Text-to-Image Generator",
    description="Type a prompt like 'a dragon made of fire flying over mountains', and click Generate!"
).launch()

"""##  Summary

With just a few lines of code, we're able to turn text into art using one of the most powerful AI models available today.  
This project is a great starting point for exploring **creative AI**, or even building your own AI tools in the future!
"""